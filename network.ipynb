{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.io import arff\n",
    "\n",
    "# Loading data into dataframe and making it work fine\n",
    "df, meta = arff.loadarff('./adult-small.arff')\n",
    "df = pd.DataFrame(df)\n",
    "str_df = df.select_dtypes([object])\n",
    "str_df = str_df.stack().str.decode('utf-8').unstack()\n",
    "for col in str_df:\n",
    "    df[col] = str_df[col]\n",
    "df = df.replace('?', np.NaN)\n",
    "\n",
    "# numeric = 0, categorical = 1\n",
    "attributeTypeDict = {\n",
    "    'age': 0,\n",
    "    'fnlwgt': 0,\n",
    "    'education-num': 0,\n",
    "    'capital-gain': 0,\n",
    "    'capital-loss': 0,\n",
    "    'hours-per-week': 0,\n",
    "    'workclass': 1,\n",
    "    'education': 1,\n",
    "    'marital-status': 1,\n",
    "    'occupation': 1,\n",
    "    'relationship': 1,\n",
    "    'race': 1,\n",
    "    'sex': 1,\n",
    "    'native-country': 1,\n",
    "}\n",
    "\n",
    "columns = df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceMissing(dataframe):\n",
    "    for col in columns:\n",
    "        if not col == 'class':\n",
    "            if attributeTypeDict.get(col) == 1:\n",
    "                # this is a categorical variable, so replace with the mode\n",
    "                dataframe[col] = dataframe[col].fillna(dataframe[col].mode()[0])\n",
    "            else:\n",
    "                # this is a numeric variable, so replace with the mean\n",
    "                dataframe[col] = dataframe[col].fillna(dataframe[col].mean())\n",
    "    return dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z Score Normalization and One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zScoreNormalize(dataframe):\n",
    "    # z score normalization\n",
    "    for column in dataframe.columns:\n",
    "        if (attributeTypeDict.get(column) == 0):\n",
    "            dataframe[column] = stats.zscore(dataframe[column])\n",
    "    return dataframe\n",
    "\n",
    "# one hot encoding\n",
    "def oneHotPreprocess(dataframe):\n",
    "    for column in dataframe.columns:\n",
    "        if(attributeTypeDict.get(column) == 1):\n",
    "            one_hot = pd.get_dummies(dataframe[column])\n",
    "            dataframe = dataframe.drop(column, axis=1)\n",
    "            dataframe = dataframe.join(one_hot)\n",
    "    return dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(data):\n",
    "    return np.maximum(0, data)\n",
    "\n",
    "def sigmoid(data):\n",
    "    return np.exp(data)/(np.exp(data)+1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed Forward and Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(nodeCounts):\n",
    "    # nodeCounts is an array containing how many nodes are in each layer\n",
    "    weights = []\n",
    "    biases = []\n",
    "\n",
    "    # loop through the node counts and create weight and bias matrices between each layer\n",
    "    for i in range(len(nodeCounts)-1):\n",
    "        currentLayerNodeCount = nodeCounts[i]\n",
    "        nextLayerNodeCount = nodeCounts[i+1]\n",
    "        weightArr = np.random.randn(nextLayerNodeCount, currentLayerNodeCount)\n",
    "        biasArr = np.random.randn(nextLayerNodeCount, 1)\n",
    "        weights.append(weightArr)\n",
    "        biases.append(biasArr)\n",
    "    return weights, biases\n",
    "\n",
    "def feed_forward(weightArray, biasArray, data):\n",
    "    activatedData = []\n",
    "    unactivatedData = []\n",
    "    for i in range(len(weightArray)):\n",
    "        if(i == 0):\n",
    "            currentLayer = data\n",
    "        else:\n",
    "            currentLayer = activatedData[i-1]\n",
    "        weightMatrix = weightArray[i]\n",
    "        biasMatrix = biasArray[i]\n",
    "        nextLayer = weightMatrix.dot(currentLayer) + biasMatrix\n",
    "        unactivatedData.append(nextLayer)\n",
    "        nextLayer = nextLayer.astype(float)\n",
    "        nextLayer = sigmoid(nextLayer)\n",
    "        activatedData.append(nextLayer)\n",
    "    return activatedData, unactivatedData\n",
    "\n",
    "# takes the class label column\n",
    "def oneHotEncode(testData):\n",
    "    classLabels = testData.copy()\n",
    "    classLabels[classLabels == '>50K'] = 1\n",
    "    classLabels[classLabels == '<=50K'] = 0\n",
    "    npClassLabels = np.array(classLabels)\n",
    "    return npClassLabels.T\n",
    "\n",
    "def sigmoid_derivative(data):\n",
    "    return sigmoid(data)*(1-sigmoid(data))\n",
    "\n",
    "def backpropagation(inputData, activatedData, unactivatedData, weights, classLabels):\n",
    "    weightDeltas = []\n",
    "    biasDeltas = []\n",
    "    entryCount = classLabels.size\n",
    "    previousError = np.array([])\n",
    "    one_hot = oneHotEncode(classLabels)\n",
    "    for i in reversed(range(len(weights))):\n",
    "        if (i == len(weights)-1):\n",
    "            # we're at the output layer and the error is diff between expected and actual outcomes\n",
    "            error = activatedData[i] - one_hot\n",
    "            deltaWeight = 1/entryCount * error.dot(activatedData[i-1].T)\n",
    "            deltaBias = 1/entryCount * np.sum(error, 1)\n",
    "            previousError = error\n",
    "            weightDeltas.append(deltaWeight)\n",
    "            biasDeltas.append(deltaBias.reshape(-1, 1))\n",
    "        elif i == 0:\n",
    "            # we are not at the output layer and need to calculate the derivative of the sigmoid function to find the error\n",
    "            error = weights[i+1].T.dot(previousError) * sigmoid_derivative(unactivatedData[i].astype(float))\n",
    "            deltaWeight = 1/entryCount * error.dot(inputData.T)\n",
    "            deltaBias = 1/entryCount * np.sum(error, 1)\n",
    "            previousError = error\n",
    "            weightDeltas.insert(0, deltaWeight)\n",
    "            biasDeltas.insert(0, deltaBias.reshape(-1, 1))\n",
    "        else:\n",
    "            error = weights[i+1].T.dot(previousError) * sigmoid_derivative(unactivatedData[i].astype(float))\n",
    "            deltaWeight = 1/entryCount * error.dot(activatedData[i-1].T)\n",
    "            deltaBias = 1/entryCount * np.sum(error, 1)\n",
    "            previousError = error\n",
    "            weightDeltas.insert(0, deltaWeight)\n",
    "            biasDeltas.insert(0, deltaBias.reshape(-1, 1))\n",
    "    return weightDeltas, biasDeltas\n",
    "\n",
    "def updateParams(weights, biases, dW, dB, learningRate):\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] = weights[i] - dW[i]*learningRate\n",
    "        biases[i] = biases[i] - dB[i]*learningRate\n",
    "    return weights, biases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number 0\n",
      "accuracy is 0.7623762376237624 \n",
      "\n",
      "iteration number 20\n",
      "accuracy is 0.9108910891089109 \n",
      "\n",
      "iteration number 40\n",
      "accuracy is 1.0 \n",
      "\n",
      "iteration number 60\n",
      "accuracy is 1.0 \n",
      "\n",
      "iteration number 80\n",
      "accuracy is 1.0 \n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# randomize\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "# separate the data and class labels\n",
    "classLabel = df['class']\n",
    "df = df.drop('class', axis=1)\n",
    "\n",
    "# get the true outputs to check against\n",
    "npClassLabels = oneHotEncode(classLabel)\n",
    "\n",
    "# replace missing values\n",
    "df = replaceMissing(df)\n",
    "\n",
    "# z score normalize\n",
    "df = zScoreNormalize(df)\n",
    "\n",
    "# one hot encode\n",
    "df = oneHotPreprocess(df)\n",
    "\n",
    "# get the input data\n",
    "numpyData = df.to_numpy().T\n",
    "testingData = numpyData.copy()\n",
    "\n",
    "# create the topology of the network\n",
    "rowCount, columnCount = numpyData.shape\n",
    "nodeCountArr = [rowCount, 100, 1]\n",
    "\n",
    "def getAccuracy(outputs, classLabels):\n",
    "    roundedOutputs = np.rint(outputs)\n",
    "    return 1-np.count_nonzero(roundedOutputs[0]-np.array(classLabels))/outputs.size\n",
    "\n",
    "def run_network(iterations, learningRate, nodeCountArr, inputData, classLabels):\n",
    "    # get initial weights and biases\n",
    "    weights, biases = init_params(nodeCountArr)\n",
    "    for i in range(iterations):\n",
    "        activatedData, unactivatedData = feed_forward(weights, biases, inputData)\n",
    "        dW, dB = backpropagation(inputData, activatedData, unactivatedData, weights, classLabels)\n",
    "        weights, biases = updateParams(weights, biases, dW, dB, learningRate)\n",
    "        if(i%20 == 0):\n",
    "            print('iteration number', i)\n",
    "            print('accuracy is', getAccuracy(activatedData[len(activatedData)-1], npClassLabels), '\\n')\n",
    "    return weights, biases\n",
    "\n",
    "w, b = run_network(100, 2, nodeCountArr, testingData, classLabel)\n",
    "\n",
    "activatedData, unactivatedData = feed_forward(w, b, testingData)\n",
    "print(getAccuracy(activatedData[len(activatedData)-1], npClassLabels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95f9eaafa776477c679170789673cdb657b512770c25e34fc9c1c2ce5abb8792"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
